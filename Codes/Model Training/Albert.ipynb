{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Albert.ipynb","provenance":[],"authorship_tag":"ABX9TyPJAnNhzPVutBSm0iocv53K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a45aRL1BZBt_","executionInfo":{"status":"ok","timestamp":1644094996159,"user_tz":-360,"elapsed":15868,"user":{"displayName":"Md. Kamrus Samad 1813059642","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISscCDtiHR2zQZxqJ-6LDPdiK7MJuZg4edxnpWQ=s64","userId":"16959572353670430778"}},"outputId":"392f214f-b260-4f47-f03f-6e18ef1e21a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqUTK6xnZ8UH","executionInfo":{"status":"ok","timestamp":1644095009588,"user_tz":-360,"elapsed":13433,"user":{"displayName":"Md. Kamrus Samad 1813059642","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISscCDtiHR2zQZxqJ-6LDPdiK7MJuZg4edxnpWQ=s64","userId":"16959572353670430778"}},"outputId":"77122e07-831d-4feb-9e12-748591a3fc95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.5 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 47.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 45.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.8 MB 38.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 5.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}]},{"cell_type":"code","source":["import sentencepiece as sp\n","sp.SentencePieceTrainer.train(input='/content/drive/MyDrive/Shadhu _Kobita/full_corpas.txt',model_prefix='spiece', vocab_size=101975)"],"metadata":{"id":"_evDAnqCcGeg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.mkdir('Own_Model')\n","os.rename('spiece.model','Own_Model/spiece.model')\n","os.rename('spiece.vocab','Own_Model/spiece.vocab')"],"metadata":{"id":"B7-Os84jcSDx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AlbertForMaskedLM,AlbertConfig,AlbertTokenizer,AutoTokenizer, AutoModel"],"metadata":{"id":"mwKnB6RzdD5Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Bangla_tokenizer = AlbertTokenizer.from_pretrained('Own_Model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbAhA-a8ZP83","executionInfo":{"status":"ok","timestamp":1644095053242,"user_tz":-360,"elapsed":986,"user":{"displayName":"Md. Kamrus Samad 1813059642","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISscCDtiHR2zQZxqJ-6LDPdiK7MJuZg4edxnpWQ=s64","userId":"16959572353670430778"}},"outputId":"7b900458-24b0-483a-b0c3-bd9df78ee3d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["file Own_Model/config.json not found\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["Bangla_tokenizer.save_pretrained('Own_Model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obhWv5kbd2fh","executionInfo":{"status":"ok","timestamp":1644095053242,"user_tz":-360,"elapsed":6,"user":{"displayName":"Md. Kamrus Samad 1813059642","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISscCDtiHR2zQZxqJ-6LDPdiK7MJuZg4edxnpWQ=s64","userId":"16959572353670430778"}},"outputId":"bc426078-56a3-4b86-ad38-e5e68d63891a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('Own_Model/tokenizer_config.json',\n"," 'Own_Model/special_tokens_map.json',\n"," 'Own_Model/spiece.model',\n"," 'Own_Model/added_tokens.json')"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from transformers import LineByLineTextDataset\n","dataset = LineByLineTextDataset(\n","    tokenizer=Bangla_tokenizer,\n","    file_path=\"/content/drive/MyDrive/Shadhu _Kobita/full_corpas.txt\",\n","    block_size=256,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"658hN8zcd423","executionInfo":{"status":"ok","timestamp":1644095167611,"user_tz":-360,"elapsed":114373,"user":{"displayName":"Md. Kamrus Samad 1813059642","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISscCDtiHR2zQZxqJ-6LDPdiK7MJuZg4edxnpWQ=s64","userId":"16959572353670430778"}},"outputId":"92dcf1cb-a3c7-4e96-b0c2-7a4cd0123ce2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["from transformers import DataCollatorForLanguageModeling\n","data_collator = DataCollatorForLanguageModeling(tokenizer=Bangla_tokenizer,mlm=True, mlm_probability=0.15)"],"metadata":{"id":"PmkM_oSyend8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config=AlbertConfig(\n","    vocab_size=101975,\n","    embedding_size=128,\n","    hidden_size=128,\n","    num_hidden_layers=2,\n","    num_attention_heads=2,\n","    intermediate_size=512,\n","    hidden_act=\"gelu\",\n","    hidden_dropout_prob=0.1,\n","    attention_probs_dropout_prob=0.1,\n","    max_position_embeddings=512,\n","    type_vocab_size=2,\n","    initializer_range=0.02,\n","    layer_norm_eps=1e-12,\n","    pad_token_id=0,\n","    bos_token_id=2,\n","    eos_token_id=3\n",")"],"metadata":{"id":"3LWdS8cDRN5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config.save_pretrained('Own_Model')"],"metadata":{"id":"PObogKaqR7YZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config=AlbertConfig.from_pretrained('Own_Model')\n","own_model = AlbertForMaskedLM(config=config)"],"metadata":{"id":"qMMYs_yaR-c8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer, TrainingArguments\n","batch_size=4\n","training_args = TrainingArguments(\n","    output_dir='bangla_albert',\n","    overwrite_output_dir=True,\n","    num_train_epochs=1,\n","    learning_rate=5e-05,\n","    per_device_train_batch_size=batch_size,\n","    save_steps=len(dataset)/batch_size,\n","    save_total_limit=2,\n","    prediction_loss_only=True\n",")\n","\n","trainer = Trainer(\n","    model=own_model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset,\n","    \n",")"],"metadata":{"id":"JmPGCxYDSAy4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7ATQ34YmSFpv","executionInfo":{"status":"ok","timestamp":1644097996664,"user_tz":-360,"elapsed":2817009,"user":{"displayName":"Md. Kamrus Samad 1813059642","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISscCDtiHR2zQZxqJ-6LDPdiK7MJuZg4edxnpWQ=s64","userId":"16959572353670430778"}},"outputId":"893c34fa-0110-4fca-b7c2-f2a07192534f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 233695\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 58424\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='58424' max='58424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [58424/58424 46:56, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>10.202800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>8.461800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>8.135900</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>8.061900</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>7.993000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>7.948700</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>7.843600</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>7.887500</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>7.867100</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>7.756200</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>7.802500</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>7.754100</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>7.684200</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>7.647000</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>7.628300</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>7.620100</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>7.527200</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>7.691400</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>7.633200</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>7.590200</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>7.495900</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>7.538200</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>7.530900</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>7.515600</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>7.464700</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>7.463900</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>7.482100</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>7.495200</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>7.513000</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>7.433200</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>7.535000</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>7.457400</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>7.397000</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>7.429500</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>7.391900</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>7.396500</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>7.371200</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>7.350800</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>7.373500</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>7.426000</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>7.326500</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>7.276200</td>\n","    </tr>\n","    <tr>\n","      <td>21500</td>\n","      <td>7.285300</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>7.275600</td>\n","    </tr>\n","    <tr>\n","      <td>22500</td>\n","      <td>7.371700</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>7.356100</td>\n","    </tr>\n","    <tr>\n","      <td>23500</td>\n","      <td>7.279000</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>7.254500</td>\n","    </tr>\n","    <tr>\n","      <td>24500</td>\n","      <td>7.314200</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>7.303500</td>\n","    </tr>\n","    <tr>\n","      <td>25500</td>\n","      <td>7.273900</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>7.343800</td>\n","    </tr>\n","    <tr>\n","      <td>26500</td>\n","      <td>7.214800</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>7.259800</td>\n","    </tr>\n","    <tr>\n","      <td>27500</td>\n","      <td>7.225100</td>\n","    </tr>\n","    <tr>\n","      <td>28000</td>\n","      <td>7.256900</td>\n","    </tr>\n","    <tr>\n","      <td>28500</td>\n","      <td>7.212500</td>\n","    </tr>\n","    <tr>\n","      <td>29000</td>\n","      <td>7.244700</td>\n","    </tr>\n","    <tr>\n","      <td>29500</td>\n","      <td>7.246900</td>\n","    </tr>\n","    <tr>\n","      <td>30000</td>\n","      <td>7.248300</td>\n","    </tr>\n","    <tr>\n","      <td>30500</td>\n","      <td>7.255300</td>\n","    </tr>\n","    <tr>\n","      <td>31000</td>\n","      <td>7.251300</td>\n","    </tr>\n","    <tr>\n","      <td>31500</td>\n","      <td>7.200700</td>\n","    </tr>\n","    <tr>\n","      <td>32000</td>\n","      <td>7.277700</td>\n","    </tr>\n","    <tr>\n","      <td>32500</td>\n","      <td>7.246100</td>\n","    </tr>\n","    <tr>\n","      <td>33000</td>\n","      <td>7.189600</td>\n","    </tr>\n","    <tr>\n","      <td>33500</td>\n","      <td>7.203700</td>\n","    </tr>\n","    <tr>\n","      <td>34000</td>\n","      <td>7.138500</td>\n","    </tr>\n","    <tr>\n","      <td>34500</td>\n","      <td>7.236800</td>\n","    </tr>\n","    <tr>\n","      <td>35000</td>\n","      <td>7.207800</td>\n","    </tr>\n","    <tr>\n","      <td>35500</td>\n","      <td>7.162900</td>\n","    </tr>\n","    <tr>\n","      <td>36000</td>\n","      <td>7.161600</td>\n","    </tr>\n","    <tr>\n","      <td>36500</td>\n","      <td>7.191200</td>\n","    </tr>\n","    <tr>\n","      <td>37000</td>\n","      <td>7.229700</td>\n","    </tr>\n","    <tr>\n","      <td>37500</td>\n","      <td>7.155500</td>\n","    </tr>\n","    <tr>\n","      <td>38000</td>\n","      <td>7.122600</td>\n","    </tr>\n","    <tr>\n","      <td>38500</td>\n","      <td>7.141000</td>\n","    </tr>\n","    <tr>\n","      <td>39000</td>\n","      <td>7.138600</td>\n","    </tr>\n","    <tr>\n","      <td>39500</td>\n","      <td>7.099600</td>\n","    </tr>\n","    <tr>\n","      <td>40000</td>\n","      <td>7.154100</td>\n","    </tr>\n","    <tr>\n","      <td>40500</td>\n","      <td>7.123300</td>\n","    </tr>\n","    <tr>\n","      <td>41000</td>\n","      <td>7.145200</td>\n","    </tr>\n","    <tr>\n","      <td>41500</td>\n","      <td>7.200400</td>\n","    </tr>\n","    <tr>\n","      <td>42000</td>\n","      <td>7.180000</td>\n","    </tr>\n","    <tr>\n","      <td>42500</td>\n","      <td>7.172000</td>\n","    </tr>\n","    <tr>\n","      <td>43000</td>\n","      <td>7.151700</td>\n","    </tr>\n","    <tr>\n","      <td>43500</td>\n","      <td>7.146300</td>\n","    </tr>\n","    <tr>\n","      <td>44000</td>\n","      <td>7.170200</td>\n","    </tr>\n","    <tr>\n","      <td>44500</td>\n","      <td>7.123800</td>\n","    </tr>\n","    <tr>\n","      <td>45000</td>\n","      <td>7.156400</td>\n","    </tr>\n","    <tr>\n","      <td>45500</td>\n","      <td>7.118300</td>\n","    </tr>\n","    <tr>\n","      <td>46000</td>\n","      <td>7.107600</td>\n","    </tr>\n","    <tr>\n","      <td>46500</td>\n","      <td>7.119400</td>\n","    </tr>\n","    <tr>\n","      <td>47000</td>\n","      <td>7.126200</td>\n","    </tr>\n","    <tr>\n","      <td>47500</td>\n","      <td>7.161500</td>\n","    </tr>\n","    <tr>\n","      <td>48000</td>\n","      <td>7.089900</td>\n","    </tr>\n","    <tr>\n","      <td>48500</td>\n","      <td>7.174000</td>\n","    </tr>\n","    <tr>\n","      <td>49000</td>\n","      <td>7.163200</td>\n","    </tr>\n","    <tr>\n","      <td>49500</td>\n","      <td>7.067400</td>\n","    </tr>\n","    <tr>\n","      <td>50000</td>\n","      <td>7.179100</td>\n","    </tr>\n","    <tr>\n","      <td>50500</td>\n","      <td>7.163800</td>\n","    </tr>\n","    <tr>\n","      <td>51000</td>\n","      <td>7.123700</td>\n","    </tr>\n","    <tr>\n","      <td>51500</td>\n","      <td>7.205400</td>\n","    </tr>\n","    <tr>\n","      <td>52000</td>\n","      <td>7.121400</td>\n","    </tr>\n","    <tr>\n","      <td>52500</td>\n","      <td>7.155700</td>\n","    </tr>\n","    <tr>\n","      <td>53000</td>\n","      <td>7.121400</td>\n","    </tr>\n","    <tr>\n","      <td>53500</td>\n","      <td>7.147600</td>\n","    </tr>\n","    <tr>\n","      <td>54000</td>\n","      <td>7.175300</td>\n","    </tr>\n","    <tr>\n","      <td>54500</td>\n","      <td>7.120800</td>\n","    </tr>\n","    <tr>\n","      <td>55000</td>\n","      <td>7.157900</td>\n","    </tr>\n","    <tr>\n","      <td>55500</td>\n","      <td>7.076200</td>\n","    </tr>\n","    <tr>\n","      <td>56000</td>\n","      <td>7.074200</td>\n","    </tr>\n","    <tr>\n","      <td>56500</td>\n","      <td>7.145000</td>\n","    </tr>\n","    <tr>\n","      <td>57000</td>\n","      <td>7.102200</td>\n","    </tr>\n","    <tr>\n","      <td>57500</td>\n","      <td>7.103900</td>\n","    </tr>\n","    <tr>\n","      <td>58000</td>\n","      <td>7.106500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=58424, training_loss=7.361065008567487, metrics={'train_runtime': 2816.8294, 'train_samples_per_second': 82.964, 'train_steps_per_second': 20.741, 'total_flos': 32334490168344.0, 'train_loss': 7.361065008567487, 'epoch': 1.0})"]},"metadata":{},"execution_count":14}]}]}