{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TokenClassification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2717,"status":"ok","timestamp":1655924762567,"user":{"displayName":"Anan Ghosh 1811796642","userId":"16277399556401054246"},"user_tz":-360},"id":"BbaOlNu__qu6","outputId":"a5998db2-1b6d-4558-a49f-3c0ba4ac17cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":902,"status":"ok","timestamp":1655924766759,"user":{"displayName":"Anan Ghosh 1811796642","userId":"16277399556401054246"},"user_tz":-360},"id":"4uWGAOlJmu__","outputId":"226bf8df-d1c7-4fed-a35e-55fa489c3abc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'banglabert'...\n","remote: Enumerating objects: 117, done.\u001b[K\n","remote: Counting objects: 100% (117/117), done.\u001b[K\n","remote: Compressing objects: 100% (92/92), done.\u001b[K\n","remote: Total 117 (delta 54), reused 73 (delta 23), pack-reused 0\u001b[K\n","Receiving objects: 100% (117/117), 1.10 MiB | 8.80 MiB/s, done.\n","Resolving deltas: 100% (54/54), done.\n"]}],"source":["!git clone https://github.com/csebuetnlp/banglabert.git"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1655924767104,"user":{"displayName":"Anan Ghosh 1811796642","userId":"16277399556401054246"},"user_tz":-360},"id":"udS7G8Evm1LO","outputId":"65c69204-f8ff-4912-926e-9f82d07fb101"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mbanglabert\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNX0FcdZn-BA","executionInfo":{"status":"ok","timestamp":1655924768649,"user_tz":-360,"elapsed":3,"user":{"displayName":"Anan Ghosh 1811796642","userId":"16277399556401054246"}},"outputId":"1b4a388a-4aaf-437d-e882-bc27b3672326"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/banglabert\n"]}],"source":["cd banglabert"]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3QZVYmiUpEQi","executionInfo":{"status":"ok","timestamp":1655924770337,"user_tz":-360,"elapsed":575,"user":{"displayName":"Anan Ghosh 1811796642","userId":"16277399556401054246"}},"outputId":"7362a045-edec-412f-acc1-cd59c86d4f25"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mfigs\u001b[0m/                requirements.txt          \u001b[01;34mtoken_classification\u001b[0m/\n","\u001b[01;34mquestion_answering\u001b[0m/  \u001b[01;34msequence_classification\u001b[0m/\n","README.md            setup.sh\n"]}]},{"cell_type":"code","source":["!pip3 install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NkcxFLIgpKWj","executionInfo":{"status":"ok","timestamp":1655924774181,"user_tz":-360,"elapsed":3846,"user":{"displayName":"Anan Ghosh 1811796642","userId":"16277399556401054246"}},"outputId":"d14492fe-528f-4a35-d5f0-ffd37b8e9ddd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/csebuetnlp/normalizer (from -r requirements.txt (line 5))\n","  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-fp8g3wkj\n","  Running command git clone -q https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-fp8g3wkj\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.1.96)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (3.17.3)\n","Requirement already satisfied: datasets==1.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.11.0)\n","Requirement already satisfied: seqeval==1.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.2.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from normalizer==0.0.1->-r requirements.txt (line 5)) (2022.6.2)\n","Requirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.7/dist-packages (from normalizer==0.0.1->-r requirements.txt (line 5)) (1.4.2)\n","Requirement already satisfied: ftfy==6.0.3 in /usr/local/lib/python3.7/dist-packages (from normalizer==0.0.1->-r requirements.txt (line 5)) (6.0.3)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0->-r requirements.txt (line 3)) (6.0.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0->-r requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0->-r requirements.txt (line 3)) (0.3.5.1)\n","Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0->-r requirements.txt (line 3)) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0->-r requirements.txt (line 3)) (4.11.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0->-r requirements.txt (line 3)) (3.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0->-r requirements.txt (line 3)) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0->-r requirements.txt (line 3)) (1.3.5)\n","Collecting huggingface-hub<0.1.0\n","  Using cached huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0->-r requirements.txt (line 3)) (2022.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0->-r requirements.txt (line 3)) (0.70.13)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2->-r requirements.txt (line 4)) (1.0.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy==6.0.3->normalizer==0.0.1->-r requirements.txt (line 5)) (0.2.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.11.0->-r requirements.txt (line 3)) (3.7.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.11.0->-r requirements.txt (line 3)) (6.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.11.0->-r requirements.txt (line 3)) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.11.0->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.11.0->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.11.0->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.11.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.11.0->-r requirements.txt (line 3)) (2022.6.15)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2->-r requirements.txt (line 4)) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2->-r requirements.txt (line 4)) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2->-r requirements.txt (line 4)) (1.4.1)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.11.0->-r requirements.txt (line 3)) (3.8.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 3)) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 3)) (2.8.2)\n","Installing collected packages: huggingface-hub\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.8.1\n","    Uninstalling huggingface-hub-0.8.1:\n","      Successfully uninstalled huggingface-hub-0.8.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","transformers 4.20.1 requires huggingface-hub<1.0,>=0.1.0, but you have huggingface-hub 0.0.19 which is incompatible.\u001b[0m\n","Successfully installed huggingface-hub-0.0.19\n"]}]},{"cell_type":"code","source":["cd token_classification"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SjD1Bs2GpUX9","executionInfo":{"status":"ok","timestamp":1655924774182,"user_tz":-360,"elapsed":9,"user":{"displayName":"Anan Ghosh 1811796642","userId":"16277399556401054246"}},"outputId":"c8681685-a0ca-4308-b787-0f3d5895234a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/banglabert/token_classification\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"id":"kpIvUGBbrMfs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655924774746,"user_tz":-360,"elapsed":569,"user":{"displayName":"Anan Ghosh 1811796642","userId":"16277399556401054246"}},"outputId":"e6581a37-10de-4179-e468-a0760a807365"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["evaluate.sh  README.md  \u001b[0m\u001b[01;34msample_inputs\u001b[0m/  token_classification.py  trainer.sh\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRszJ7kEylGI","outputId":"13546eab-f77f-4953-f8e9-35734bafd368","executionInfo":{"status":"ok","timestamp":1655924779483,"user_tz":-360,"elapsed":3607,"user":{"displayName":"Anan Ghosh 1811796642","userId":"16277399556401054246"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: huggingface-hub\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.0.19\n","    Uninstalling huggingface-hub-0.0.19:\n","      Successfully uninstalled huggingface-hub-0.0.19\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datasets 1.11.0 requires huggingface-hub<0.1.0, but you have huggingface-hub 0.8.1 which is incompatible.\u001b[0m\n","Successfully installed huggingface-hub-0.8.1\n"]}]},{"cell_type":"code","source":["!python token_classification.py --model_name_or_path \"/content/drive/MyDrive/downstreaming_task /bnbert-20220524T105128Z-001/bnbert\" --dataset_dir \"/content/banglabert/token_classification/sample_inputs\" --output_dir \"outputs/\" --learning_rate=2e-5 --warmup_ratio 0.1 --gradient_accumulation_steps 2 --weight_decay 0.1 --lr_scheduler_type \"linear\" --per_device_train_batch_size=16 --per_device_eval_batch_size=16 --max_seq_length 512 --logging_strategy \"epoch\" --save_strategy \"epoch\" --evaluation_strategy \"epoch\" --num_train_epochs=10  --do_train --do_eval"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YpEwHZQLv44b","executionInfo":{"status":"ok","timestamp":1655924851003,"user_tz":-360,"elapsed":4628,"user":{"displayName":"Anan Ghosh 1811796642","userId":"16277399556401054246"}},"outputId":"97e6a7f0-3a05-4678-c33b-d5419cd74992"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["06/22/2022 19:07:41 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","06/22/2022 19:07:41 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=IntervalStrategy.EPOCH,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_min_num_params=0,\n","full_determinism=False,\n","gradient_accumulation_steps=2,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=2e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=outputs/runs/Jun22_19-07-41_59450927cdfb,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.EPOCH,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=10.0,\n","optim=OptimizerNames.ADAMW_HF,\n","output_dir=outputs/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=16,\n","per_device_train_batch_size=16,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=outputs/,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=IntervalStrategy.EPOCH,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.1,\n","warmup_steps=0,\n","weight_decay=0.1,\n","xpu_backend=None,\n",")\n","06/22/2022 19:07:41 - WARNING - datasets.builder - Using custom data configuration default-6118b862fb5a580d\n","06/22/2022 19:07:41 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-6118b862fb5a580d/0.0.0)\n","Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-6118b862fb5a580d/0.0.0...\n","\r  0% 0/3 [00:00<?, ?it/s]\r100% 3/3 [00:00<00:00, 14331.33it/s]\n","06/22/2022 19:07:41 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n","06/22/2022 19:07:41 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n","\r  0% 0/3 [00:00<?, ?it/s]\r100% 3/3 [00:00<00:00, 1672.59it/s]\n","06/22/2022 19:07:41 - INFO - datasets.builder - Generating split train\n","\r0 tables [00:00, ? tables/s]\r                            \r06/22/2022 19:07:41 - INFO - datasets.builder - Generating split validation\n","\r0 tables [00:00, ? tables/s]\r                            \r06/22/2022 19:07:41 - INFO - datasets.builder - Generating split test\n","\r0 tables [00:00, ? tables/s]\r                            \rDataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-6118b862fb5a580d/0.0.0. Subsequent calls will reuse this data.\n","\r  0% 0/3 [00:00<?, ?it/s]\r100% 3/3 [00:00<00:00, 880.42it/s]\n","[INFO|configuration_utils.py:657] 2022-06-22 19:07:41,134 >> loading configuration file /content/drive/MyDrive/downstreaming_task /bnbert-20220524T105128Z-001/bnbert/config.json\n","[INFO|configuration_utils.py:708] 2022-06-22 19:07:41,138 >> Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/downstreaming_task /bnbert-20220524T105128Z-001/bnbert\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 101,\n","  \"classifier_dropout\": null,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 102,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 312,\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 1248,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 4,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertTokenizerFast\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|tokenization_utils_base.py:1701] 2022-06-22 19:07:41,141 >> Didn't find file /content/drive/MyDrive/downstreaming_task /bnbert-20220524T105128Z-001/bnbert/tokenizer.json. We won't load it.\n","[INFO|tokenization_utils_base.py:1701] 2022-06-22 19:07:41,141 >> Didn't find file /content/drive/MyDrive/downstreaming_task /bnbert-20220524T105128Z-001/bnbert/added_tokens.json. We won't load it.\n","[INFO|tokenization_utils_base.py:1701] 2022-06-22 19:07:41,141 >> Didn't find file /content/drive/MyDrive/downstreaming_task /bnbert-20220524T105128Z-001/bnbert/special_tokens_map.json. We won't load it.\n","[INFO|tokenization_utils_base.py:1779] 2022-06-22 19:07:41,142 >> loading file /content/drive/MyDrive/downstreaming_task /bnbert-20220524T105128Z-001/bnbert/vocab.txt\n","[INFO|tokenization_utils_base.py:1779] 2022-06-22 19:07:41,142 >> loading file None\n","[INFO|tokenization_utils_base.py:1779] 2022-06-22 19:07:41,142 >> loading file None\n","[INFO|tokenization_utils_base.py:1779] 2022-06-22 19:07:41,142 >> loading file None\n","[INFO|tokenization_utils_base.py:1779] 2022-06-22 19:07:41,142 >> loading file /content/drive/MyDrive/downstreaming_task /bnbert-20220524T105128Z-001/bnbert/tokenizer_config.json\n","[INFO|modeling_utils.py:2105] 2022-06-22 19:07:41,215 >> loading weights file /content/drive/MyDrive/downstreaming_task /bnbert-20220524T105128Z-001/bnbert/pytorch_model.bin\n","[WARNING|modeling_utils.py:2474] 2022-06-22 19:07:41,443 >> Some weights of the model checkpoint at /content/drive/MyDrive/downstreaming_task /bnbert-20220524T105128Z-001/bnbert were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:2486] 2022-06-22 19:07:41,443 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at /content/drive/MyDrive/downstreaming_task /bnbert-20220524T105128Z-001/bnbert and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","06/22/2022 19:07:41 - WARNING - datasets.fingerprint - Parameter 'function'=<function main.<locals>.normalize_example at 0x7f2fa277c8c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","Running normalization on dataset:   0% 0/5 [00:00<?, ?ex/s]06/22/2022 19:07:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6118b862fb5a580d/0.0.0/cache-1c80317fa3b1799d.arrow\n","Running normalization on dataset: 100% 5/5 [00:00<00:00, 1169.57ex/s]\n","06/22/2022 19:07:41 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.normalize_example at 0x7f2fa277c8c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n","Running normalization on dataset:   0% 0/5 [00:00<?, ?ex/s]06/22/2022 19:07:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6118b862fb5a580d/0.0.0/cache-bdd640fb06671ad1.arrow\n","Running normalization on dataset: 100% 5/5 [00:00<00:00, 1548.40ex/s]\n","06/22/2022 19:07:41 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.normalize_example at 0x7f2fa277c8c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n","Running normalization on dataset:   0% 0/5 [00:00<?, ?ex/s]06/22/2022 19:07:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6118b862fb5a580d/0.0.0/cache-3eb13b9046685257.arrow\n","Running normalization on dataset: 100% 5/5 [00:00<00:00, 1725.77ex/s]\n","06/22/2022 19:07:41 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.tokenize_and_align_labels at 0x7f2fa2667830> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n","Running tokenizer on dataset:   0% 0/1 [00:00<?, ?ba/s]06/22/2022 19:07:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6118b862fb5a580d/0.0.0/cache-23b8c1e9392456de.arrow\n","Running tokenizer on dataset: 100% 1/1 [00:00<00:00, 307.79ba/s]\n","06/22/2022 19:07:41 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.tokenize_and_align_labels at 0x7f2fa2667830> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n","Running tokenizer on dataset:   0% 0/1 [00:00<?, ?ba/s]\n","Traceback (most recent call last):\n","  File \"token_classification.py\", line 494, in <module>\n","    main()\n","  File \"token_classification.py\", line 347, in main\n","    desc=\"Running tokenizer on dataset\",\n","  File \"/usr/local/lib/python3.7/dist-packages/datasets/dataset_dict.py\", line 489, in map\n","    for k, dataset in self.items()\n","  File \"/usr/local/lib/python3.7/dist-packages/datasets/dataset_dict.py\", line 489, in <dictcomp>\n","    for k, dataset in self.items()\n","  File \"/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\", line 1682, in map\n","    desc=desc,\n","  File \"/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\", line 185, in wrapper\n","    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/datasets/fingerprint.py\", line 397, in wrapper\n","    out = func(self, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\", line 2020, in _map_single\n","    offset=offset,\n","  File \"/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\", line 1906, in apply_function_on_filtered_inputs\n","    function(*fn_args, effective_indices, **fn_kwargs) if with_indices else function(*fn_args, **fn_kwargs)\n","  File \"token_classification.py\", line 332, in tokenize_and_align_labels\n","    label_ids.append(label_to_id[label[word_idx]])\n","KeyError: 'B-LOC'\n"]}]},{"cell_type":"code","source":["!rm -rf /content/banglabert"],"metadata":{"id":"AJeSF61I27ft","executionInfo":{"status":"ok","timestamp":1655924754916,"user_tz":-360,"elapsed":330,"user":{"displayName":"Anan Ghosh 1811796642","userId":"16277399556401054246"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"QuXEAPBFEsoB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"s0rznitREslm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"FUjVeNCJEsi2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Models/CSE498\")"],"metadata":{"id":"jdQv3rS_EsdZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"hHJn4b3JE2Xj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data[0]"],"metadata":{"id":"bqhFV4lyHYao","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655917048267,"user_tz":-360,"elapsed":441,"user":{"displayName":"Md. Kamrus Samad 1813059642","userId":"16959572353670430778"}},"outputId":"f6db7cd8-d577-497f-f5cc-d0b0e25127a1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'tags': ['NC',\n","  'PPR',\n","  'JQ',\n","  'NC',\n","  'VM',\n","  'PU',\n","  'PU',\n","  'NC',\n","  'NC',\n","  'AMN',\n","  'NC',\n","  'PP',\n","  'VM',\n","  'VAUX',\n","  'JJ',\n","  'NP',\n","  'NP',\n","  'PU'],\n"," 'tokens': ['নামটা',\n","  'আমার',\n","  'খুব',\n","  'পছন্দ',\n","  'হয়েছে',\n","  'মুখের',\n","  'মুক্তোগুলো',\n","  'আবার',\n","  'ঘরের',\n","  'মধ্যে',\n","  'ছড়িয়ে',\n","  'দিলো',\n","  'কেশবতী',\n","  'এলিজাবেথ',\n","  'গিবসন',\n","  '৷']}"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# c = 0\n","# for i in data:\n","#   if len(i['tokens']) != len(i['tags']):\n","#     data.remove(i)\n","#     c+=1\n","# c"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XBp9I4DkE0rN","executionInfo":{"status":"ok","timestamp":1655914135229,"user_tz":-360,"elapsed":366,"user":{"displayName":"Md. Kamrus Samad 1813059642","userId":"16959572353670430778"}},"outputId":"a3f0bfe9-410f-4a98-8e57-da99091bc63e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["for i in data:\n","  tokenized_input = tokenizer(i[\"tokens\"], is_split_into_words=True)\n","  tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B-Y85MfDKi2q","executionInfo":{"status":"ok","timestamp":1655916583034,"user_tz":-360,"elapsed":421,"user":{"displayName":"Md. Kamrus Samad 1813059642","userId":"16959572353670430778"}},"outputId":"f1482f91-ef22-4738-eda2-70bd2a323dae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]',\n"," 'আমি',\n"," 'আগে',\n"," 'তার',\n"," 'আকা',\n"," 'দটি',\n"," 'ঘোডার',\n"," 'ছবি',\n"," 'দেখেছি',\n"," '৷',\n"," '[SEP]']"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# len(example[f\"{task}_tags\"]),\n","\n","# len(tokenized_input[\"input_ids\"])\n","\n","# print(tokenized_input.word_ids())"],"metadata":{"id":"_zj8uBRnmHLc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n","\n","    labels = []\n","    for i, label in enumerate(examples[f\"tags\"]):\n","      print(label)\n","      word_ids = tokenized_inputs.word_ids(batch_index=i)\n","      # print(word_ids)\n","      previous_word_idx = None\n","      label_ids = []\n","      # print(label)\n","      for word_idx in word_ids:\n","        print(word_idx)\n","        if word_idx is None:\n","          label_ids.append(-100)\n","        elif word_idx != previous_word_idx:\n","          label_ids.append(label[word_idx])\n","        else:\n","          label_ids.append(-100)\n","        previous_word_idx = word_idx\n","      labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"],"metadata":{"id":"EO1BkSZSH6WO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in data:\n","  t = tokenize_and_align_labels(i)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"Jpf15tsAH9jK","executionInfo":{"status":"error","timestamp":1655921044020,"user_tz":-360,"elapsed":585,"user":{"displayName":"Md. Kamrus Samad 1813059642","userId":"16959572353670430778"}},"outputId":"a0c4e0cd-a931-4847-ec64-724ec42e566b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NC\n","None\n","0\n","1\n","2\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-108-f460ecdb6ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_and_align_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-107-7e6b1fa93fb2>\u001b[0m in \u001b[0;36mtokenize_and_align_labels\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0mlabel_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mword_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mprevious_word_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m           \u001b[0mlabel_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mlabel_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: string index out of range"]}]},{"cell_type":"code","source":["lst = data[0]['tags']"],"metadata":{"id":"xDoe_UrrX8wo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lst"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4W5Ig50gZl8F","executionInfo":{"status":"ok","timestamp":1655917940748,"user_tz":-360,"elapsed":5,"user":{"displayName":"Md. Kamrus Samad 1813059642","userId":"16959572353670430778"}},"outputId":"332226fa-9dbc-4b29-b8a0-1e9a19b8aa29"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['NC',\n"," 'PPR',\n"," 'JQ',\n"," 'NC',\n"," 'VM',\n"," 'PU',\n"," 'PU',\n"," 'NC',\n"," 'NC',\n"," 'AMN',\n"," 'NC',\n"," 'PP',\n"," 'VM',\n"," 'VAUX',\n"," 'JJ',\n"," 'NP',\n"," 'NP',\n"," 'PU']"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["e = enumerate(lst)\n","print(list(e))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QW5H6RzRX8qK","executionInfo":{"status":"ok","timestamp":1655917952074,"user_tz":-360,"elapsed":363,"user":{"displayName":"Md. Kamrus Samad 1813059642","userId":"16959572353670430778"}},"outputId":"633f9187-d3da-469a-940a-648502c91e87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[(0, 'NC'), (1, 'PPR'), (2, 'JQ'), (3, 'NC'), (4, 'VM'), (5, 'PU'), (6, 'PU'), (7, 'NC'), (8, 'NC'), (9, 'AMN'), (10, 'NC'), (11, 'PP'), (12, 'VM'), (13, 'VAUX'), (14, 'JJ'), (15, 'NP'), (16, 'NP'), (17, 'PU')]\n"]}]},{"cell_type":"code","source":["for i, label in enumerate(lst):\n","  print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqAcbz6ZYqaa","executionInfo":{"status":"ok","timestamp":1655917955104,"user_tz":-360,"elapsed":354,"user":{"displayName":"Md. Kamrus Samad 1813059642","userId":"16959572353670430778"}},"outputId":"999e359b-451a-41c2-c72a-e604059dd0ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n"]}]}]}